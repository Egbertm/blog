---
layout: post
title:  "数据挖掘算法（三）决策树ID3"
date:   2016-12-31 23:06:05
categories: 算法
tags:  算法 决策树
---
* content  
{:toc}  

### 1 算法的概述  
ID3算法（Iterative Dichotomiser 3 迭代二叉树3代）【1】是一个由Ross Quinlan发明的用于决策树的算法。
这个算法是建立在奥卡姆剃刀的基础上：越是小型的决策树越优于大的决策树（简单理论）。尽管如此，该算法也不是总是生成最小的树形结构。而是一个启发式算法。  




### 2 算法的原理
  
机器学习中，决策树是一个预测模型；他代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表的某个可能的属性值，而每个叶结点则对应从根节点到该叶节点所经历的路径所表示的对象的值。决策树仅有单一输出，若欲有复数输出，可以建立独立的决策树以处理不同输出。 数据挖掘中决策树是一种经常要用到的技术，可以用于分析数据，同样也可以用来作预测。
从数据产生决策树的机器学习技术叫做决策树学习,通俗说就是决策树。
一个决策树包含三种类型的节点：  
决策节点：通常用矩形框来表示  
机会节点：通常用圆圈来表示  
终结点：通常用三角形来表示,如图所示  
![http://o886hn2n8.bkt.clouddn.com//suanfa/%E7%AE%97%E6%B3%95ID3_1.png](http://o886hn2n8.bkt.clouddn.com//suanfa/%E7%AE%97%E6%B3%95ID3_1.png)  

#### 2.1 决策树的构造
决策的构造关键在于如何选择分裂属性。关于分裂属性，就是在某个节点处安装某一特征的不同的划分构造不同的分支，其目的是让各个分裂属性尽可能的“纯”。最纯的时候代表当前的子集是属于同一个类别。
#### 2.2ID3算法
在信息论中，采用信息熵表示信息的信息的价值，同时也表示消息的混乱度，熵值越大代表越混乱。而信息增益表示信息的纯度，增益越大，纯度越高。ID3就是根据信息增益来选择属性的。选择分裂后信息增益最大的属性进行分裂。
信息熵表示如下：  

$$IE\left(i\right)=-\sum_{j=1}^m f \left(i,j\right)log_2 f\left(i,j\right)$$

#### 2.3 算法的优点  
1. 决策树ID3算法易于理解  

2. 即能处理数据型的也能处理常规型的数据  

3. 在相对较短的时间内能够对大型的数据集做出可行且较好的结果  
  
#### 2.4 算法的缺点
  
1 比较偏向于选择属性值多的类别，后有C4.5算法对它进行了改进。  

### 3 算法的代码实现
该算法使用的是Java语言实现，在Windows7系统JDK1.8平台下测试通过，以下是代码及代码描述：

``` java
    
    package suanfa;

    import java.io.BufferedReader;
    import java.io.FileInputStream;
    import java.io.FileWriter;
    import java.io.IOException;
    import java.io.InputStreamReader;
    import java.util.ArrayList;
    import java.util.HashMap;
    import java.util.HashSet;
    import java.util.Map;
    import java.util.Set;
    
    import org.dom4j.Document;
    import org.dom4j.DocumentHelper;
    import org.dom4j.Element;
    import org.dom4j.io.XMLWriter;
    
    class Utils{
    //用于从文件中获取数据集
    public static ArrayList<ArrayList<String>> loadDataSet(String file) throws IOException{
        ArrayList<ArrayList<String>> dataSet=new ArrayList<ArrayList<String>>();
        FileInputStream fis=new FileInputStream(file);
        InputStreamReader isr=new InputStreamReader(fis,"UTF-8");
        BufferedReader br=new BufferedReader(isr);
        String line="";
        line=br.readLine();
        while((line=br.readLine())!=null){
            String[] words=line.split(",");
            ArrayList<String> data=new ArrayList<String>();
            for(int i=0;i<words.length;i++){
                data.add(words[i]);
            }
            dataSet.add(data);
        }
        br.close();
        isr.close();
        fis.close();
        return dataSet;
    }
    //用于从文件中获取特征
    public static ArrayList<String> loadFeature(String file) throws IOException{
        FileInputStream fis=new FileInputStream(file);
        InputStreamReader isr=new InputStreamReader(fis,"UTF-8");
        BufferedReader br=new BufferedReader(isr);
        
        String[] line=br.readLine().split(",");
        ArrayList<String> feature=new ArrayList<String>();
        for(int i=0;i<line.length-1;i++){
            feature.add(line[i]);
        }
        br.close();
        isr.close();
        fis.close();
        return feature;
    }
    //用于获得数据集中的类别列表
    public static ArrayList<String> getClassList(ArrayList<ArrayList<String>> dataSet){
        ArrayList<String> classList=new ArrayList<String>();
        int length=dataSet.get(0).size();
        for(ArrayList<String> data:dataSet){
            String label=data.get(length-1);
            classList.add(label);
        }
        return classList;
    }
    //返回数据集中的特征数
    public static int featureNum(ArrayList<ArrayList<String>> dataList){
        int len=dataList.get(0).size()-1;
        return len;
    }
    
    
    //用于获得数据集中第index列的map映射，方便后续的遍历value和计算熵
    public static Map<String,Integer> getSubMap(ArrayList<ArrayList<String>> dataSet,int index){
        int total=dataSet.size();
        Map<String,Integer> subMap=new HashMap();
        for(ArrayList<String> data:dataSet){
            String lable=data.get(index);
            if(subMap.get(lable)==null){
                subMap.put(lable,1);
            }else{
                subMap.put(lable,subMap.get(lable)+1);
            }
        }
        return subMap;
    }
    //打印map，用于debug的时候
    public static void showMap(Map<String,Integer> map){
        for(Map.Entry<String,Integer> entry:map.entrySet()){
            System.out.println(entry.getKey()+":"+entry.getValue());
        }
    }
    //求熵
    public static double getEntropy(ArrayList<ArrayList<String>> dataSet,int index){
        int total=dataSet.size();
        Map<String,Integer> subMap=getSubMap(dataSet,index);        
        double entropy=0;
        for(Map.Entry<String,Integer> entry:subMap.entrySet()){
            double temp=entry.getValue()*1.0/total;
            entropy+=temp*(Math.log(temp)/Math.log(2));
        }
        return -entropy;
    }
    //求信息增益最大的分割点
    public static String bestFeatureSplit(ArrayList<ArrayList<String>> dataSet,ArrayList<String> featureList){
        int length=dataSet.get(0).size();
        double totalEntropy=getEntropy(dataSet,length-1);
        
        
        
        int featureNum=dataSet.get(0).size()-1;
        int index=-1;
        double maxInfoGain=-1;
        for(int i=0;i<featureNum;i++){
            double entropy=getEntropy(dataSet,i);
            Map<String,Integer> map=getSubMap(dataSet,i);//获得该特征下的map
            ArrayList<String> lableList=new ArrayList<String>();
            double entropySum=0;
            
            for(Map.Entry<String,Integer> entry:map.entrySet()){//这里的Di就是map中的特征的value值
                Map<String,Integer> subMap=new HashMap();
                
                
                for(ArrayList<String> data:dataSet){
                    if(data.get(i).compareTo(entry.getKey())==0){
                        if(subMap.get(data.get(length-1))==null){
                            
                            subMap.put(data.get(length-1),1);
                        }else{
                            subMap.put(data.get(length-1),subMap.get(data.get(length-1))+1);
                        }
                    }
                }
                double x=0;
                for(Map.Entry<String,Integer> subEntry:subMap.entrySet()){
                    double temp=subEntry.getValue()*1.0/entry.getValue();
                    x+=temp*(Math.log(temp)/Math.log(2));
                }
                
                entropySum+=-x*(entry.getValue())/dataSet.size();
            }
            entropySum=totalEntropy-entropySum;
            if(entropySum>maxInfoGain){
                index=i;
                maxInfoGain=entropySum;
            }
        }
        return featureList.get(index);
    }
    //分割数据集，index为特征的下标
    public static ArrayList<ArrayList<String>> splitDataSet(ArrayList<ArrayList<String>> dataSet,int index,String value){
        ArrayList<ArrayList<String>> subDataSet=new ArrayList<ArrayList<String>>();
        for(ArrayList<String> data:dataSet){        
            if(data.get(index).compareTo(value)==0){
                ArrayList<String> temp=new ArrayList<String>();
                for(int i=0;i<data.size();i++){
                    if(i!=index){
                        temp.add(data.get(i));
                    }
                }
                subDataSet.add(temp);
            }
        }
        return subDataSet;
    }
    //list-》map
    public static Map<String,Integer> arrayToMap(ArrayList<String> list){
        Map<String,Integer> map=new HashMap();
        for(String word:list){
            if(map.get(word)==null){
                map.put(word,1);
            }else{
                map.put(word,map.get(word)+1);
            }
        }
        return map;
    }
    //求label中某个数量最多的类别
    public static String major(ArrayList<String> labelList){
        Map<String,Integer> map=arrayToMap(labelList);
        int max=0;
        String label="";
        for(Map.Entry<String,Integer> entry:map.entrySet()){
            if(entry.getValue()>max){
                label=entry.getKey();
            }
        }
        return label;
    }
    
    public static Set<String> getValueFromDataSet(ArrayList<ArrayList<String>> dataSet,int index){
        ArrayList<String> values=new ArrayList<String>();
        for(ArrayList<String> data:dataSet){
            try{
            values.add(data.get(index));
            }catch(Exception e){
                
                System.out.println("index is "+index);
            }
        }
        Set<String> set=new HashSet();
        for(String value:values){
            set.add(value);
        }
        return set;
    }
    
    public static ArrayList<String> copyArrayList(ArrayList<String> src){
        ArrayList<String> dest=new ArrayList<String>();
        for(String s:src){
            dest.add(s);
        }
        return dest;
    }
    
    
    public static void showArrayList(ArrayList<ArrayList<String>> dataSet){
        for(ArrayList<String> data:dataSet){
            System.out.println(data);
        }
    }
    
    }


    public class Call {
    
    
    public static int  createTree(ArrayList<ArrayList<String>> dataSet,ArrayList<String> featureList,Element e){
        ArrayList<String> labelList=Utils.getClassList(dataSet);//获取数据集中label的列表
        if(Utils.arrayToMap(labelList).size()==1){//表示label中只有一种类别，所以此时不需要再分类了
            e.addText(labelList.get(0));
            return 1;
        }
        if(dataSet.get(0).size()==1){//表示此时已经没有特征了，所以也不需要再继续了，此时以label中最多的类别为该节点的类别
            e.addText(Utils.major(labelList));
            return 1;
        }
        
        ArrayList<String> subFeatureList=Utils.copyArrayList(featureList);
        String feature=Utils.bestFeatureSplit(dataSet,featureList);
        subFeatureList.remove(feature);
        int index=featureList.indexOf(feature);
        Set<String> valueSet=Utils.getValueFromDataSet(dataSet,index);
        for(String value:valueSet){
        	System.out.println("TTTTT"+feature);
             Element next=e.addElement(feature);//后来放到这里之后，xml的输出就正确了,原因在于每递归一次就需要创建一个element，所以应该在for内创建。
             next.addAttribute("value",value);
             ArrayList<ArrayList<String>> subDataSet=Utils.splitDataSet(dataSet,index,value);
             System.out.println("$$$$$$$$$$$$$$$$$$$$");
             showDataset(subDataSet);
             System.out.println(">>>>>>>>>>>>>>>>>>>>");
             createTree(subDataSet,subFeatureList,next);
        }
        return 1;
    }
    public static void showDataset(ArrayList<ArrayList<String>> set){
    	for(ArrayList<String> array:set){
    		for(String st:array){
    			System.out.print(st+",");
    		}
    		System.out.println("");
    	}
    }
    public static void main(String[] args) throws IOException {
        // TODO Auto-generated method stub
        String file="D:/D.txt";
        String xml="D:/DT1.xml";
        ArrayList<ArrayList<String>> dataSet=Utils.loadDataSet(file);
        ArrayList<String> featureList=Utils.loadFeature(file);
        Document document = DocumentHelper.createDocument();
        Element root = document.addElement("DecisionTree");
        createTree(dataSet,featureList,root);
        XMLWriter writer=new XMLWriter(new FileWriter(xml));
        writer.write(document);
        writer.close();
        System.out.println("finished");
    }

    }
    
```
  
以上是ID3的简单的实现：方法前有描述，不过多的介绍。  

### 4 实验与分析

实验结果如下：  
    
    <DecisionTree>
    <outlook value="rainy">
    <windy value="TRUE">0</windy>
    <windy value="FALSE">1</windy>
    </outlook>
    <outlook value="overcast">1</outlook>
    <outlook value="sunny">
    <humidity value="normal">1</humidity>
    <humidity value="high">0</humidity>
    </outlook>
    </DecisionTree>
    
实验基本能够把决策树给写进文件，下一步需要做的是利用生成的决策树预测分类，并且为了提高程序的健壮性，需要对不同的数据集进行测试处理。当然了一棵决策树不能在实验时得到更好的效果，需要利用决策树的一些其他算法，像随机森林，C4.5算法等。  

### 参考文献

【1】[https://zh.wikipedia.org](https://zh.wikipedia.org "https://zh.wikipedia.org")  
【2】[http://www.cnblogs.com/leoo2sk/archive/2010/09/19/decision-tree.html](http://www.cnblogs.com/leoo2sk/archive/2010/09/19/decision-tree.html "http://www.cnblogs.com/leoo2sk/archive/2010/09/19/decision-tree.html")  