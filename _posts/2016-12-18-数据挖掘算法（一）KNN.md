---
layout: post
title:  "数据挖掘算法（一）KNN算法"
date:   2016-12-18 23:06:05
categories: 算法
tags:  算法 KNN
---
* content  
{:toc}  

### 1 概述
KNN算法是K-Nearest Neighbor,它是十大数据挖掘算法之一；该算法是一惰性算法，它的精度直接依赖与测试集的大小，通常情况下对于对于时间性能要求不高的算法可以考虑使用KNN算法，该算法的优点是，简单，无需估计参数；在一些如基因多分类，蛋白交互等领域有很好的应用。下面介绍算法的理论知识。  




### 2 算法的理论介绍  
算法的理论比较简单，设计到两方面的内容，一个是知识表达的系统，决策表。它是一个非空的对象集合我们用$U$表示，每个对象是若干个属性值构成的一特征向量我们用$X$表示这个特征向量，而属性的集合我们用$R$表示，$R=r \bigcup c$ ,$r$是条件属性的集合，$c$是决策属性的集合，其中$r \bigcap c=\Phi$是一个空集。对于更加严格的决策表的定义参考  
KNN 分类的过程有以下几步：  
（1）记录的特征表示，即对数据文件用决策表的方式表示。
（2）对于测试集中的任意一个未知的样本$x_i$,遍历整个训练集，求出训练集$k$个与这个未知样本的距离，此处的计算距离可以用欧氏距离计算。距离最近的$k$个对象，每个对象都有一个已知的类别，求出相同类别数最多的类别作为改未知样本的类别。
（3）遍历整个测试集，求出预测的类别与原有的测试集对应对象的类别，进行比较。
（4）计算分类模型的正确率。
### 3 算法在预测分类上的实现 
该算法使用的是Java语言实现，在Windows7系统JDK1.8平台下测试通过，同时数据集的来源是UCI加利福尼亚大学公开的数据集，对里面的数据集进行了测试实验。以下是代码及代码描述：
    
    package suanfa;

    import java.io.BufferedReader;
    import java.io.File;
    import java.io.FileNotFoundException;
    import java.io.FileReader;
    import java.io.IOException;
    import java.util.ArrayList;
    import java.util.Collections;
    import java.util.Comparator;
    import java.util.HashMap;
    import java.util.Map;
    import java.util.Map.Entry;
    import java.util.Set;
    
    public class KNN {
	
	public static ArrayList<ArrayList<String>> loadFile(String path){
		ArrayList<ArrayList<String>> lineList = new ArrayList<ArrayList<String>>();
		File file = new File(path);
		if (!file.exists()) {
			return null;
		} else {
			try {
				FileReader fin = new FileReader(file);
				BufferedReader br = new BufferedReader(fin);
				String line = "";
				line=br.readLine(); //定位到第二行。
				while ((line = br.readLine()) != null) {
					if ("".equals(line)){
						break;
					} else {
						ArrayList<String> lineWord = new ArrayList<String>();
						String[] words = line.split(","); 
						for (String st: words) {
							lineWord.add(st);
						}
						lineList.add(lineWord);
					}
				}
				br.close();
				fin.close();
			} catch (FileNotFoundException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			} catch (IOException e) {
				e.printStackTrace();
			}
		}
		return lineList;
	}
	public static ArrayList<String> getColum(ArrayList<ArrayList<String>> dataset,int index) {
		ArrayList<String> columList = new ArrayList<String>();
		for (int i=0;i<dataset.size();i++){
			columList.add(dataset.get(i).get(index));
		}
		Collections.sort(columList,new Comparator<String>() {

			@Override
			public int compare(String o1, String o2) {
				// TODO Auto-generated method stub
				if ((Double.parseDouble(o1)-Double.parseDouble(o2))>0) {
					return 1;
				} else if ((Double.parseDouble(o1)-Double.parseDouble(o2))<0) {
					return -1;
				} else {
					return 0;
				}
			}
		});
		return columList;
	}
	public static ArrayList<ArrayList<String>> getMaxMin(ArrayList<ArrayList<String>> dataset) {
		ArrayList<ArrayList<String>> maxMinList = new ArrayList<ArrayList<String>>();
		for (int i=0;i<dataset.get(0).size();i++) {
			ArrayList<String> maxMin = new ArrayList<String>();
			ArrayList<String> colum = getColum(dataset, i);
			maxMin.add(colum.get(0));
			maxMin.add(colum.get(dataset.size()-1));
			maxMinList.add(maxMin);
		}
		return maxMinList;
	}
	public static String calData(ArrayList<String> array,String str) {
		double max = Double.parseDouble(array.get(1));
		double min = Double.parseDouble(array.get(0));
		return String.valueOf((Double.parseDouble(str)-min)*1.0/(max-min));
	}
	public static ArrayList<ArrayList<String>> formatData(ArrayList<ArrayList<String>> dataset) {
		ArrayList<ArrayList<String>> maxMinList = getMaxMin(dataset);
		ArrayList<ArrayList<String>> autoData = new ArrayList<ArrayList<String>>();
		for (ArrayList<String> array : dataset) {
			ArrayList<String> data = new ArrayList<String>();
			for (int k=0;k<array.size();k++) {
				data.add(calData(maxMinList.get(k), array.get(k)));
			}
			autoData.add(data);
		}
		return autoData;
	}
	public static void showArray(ArrayList<ArrayList<String>> arrayList) {
		for (ArrayList<String> array : arrayList){
			for(String str : array){
				System.out.print(str + ",");
			}
			System.out.print("\n");
		}
	}
	public static double caldistance(ArrayList<String> arr1,ArrayList<String> arr2) {
		double distance = 0.0;
		double dx = 0.0;
		for (int i=0;i<arr1.size()-1;i++) {
			dx = Double.parseDouble(arr1.get(i))-Double.parseDouble(arr2.get(i));
			distance = Math.sqrt(dx * dx);
		}
		return distance;
	}
	public static String getFeatureLabel(ArrayList<ArrayList<String>> dataset, ArrayList<String> item,int k) {
		HashMap<Integer,Double> resultMap = new HashMap<Integer,Double>();
		ArrayList<String> featureList = new ArrayList<String>();
		String label = null;
		int max=-1;
		int i=0;
		for (ArrayList<String> arr : dataset) {
			resultMap.put(i++, caldistance(arr, item));
		}
		ArrayList<Map.Entry<Integer, Double>> list = new ArrayList<>();
		for (Map.Entry<Integer, Double> ent : resultMap.entrySet()){
			list.add(ent);
		}
		Collections.sort(list,new Comparator<Map.Entry<Integer, Double>>() {

			@Override
			public int compare(Entry<Integer, Double> o1, Entry<Integer, Double> o2) {
				// TODO Auto-generated method stub
				if ((o1.getValue()-o2.getValue())>0) {
					
					return 1;
				} else if ((o1.getValue()-o2.getValue())<0) {
					return -1;
				} else {
					return 0;
				}
			}
		});
		for (int j=0;j<k;j++) {
			featureList.add(dataset.get(list.get(j).getKey()).get(dataset.get(0).size()-1));
		}
		Map<String,Integer> map = new HashMap<String,Integer>();
		for (String str : featureList) {
			if (map.containsKey(str)) {
				map.put(str, map.get(str)+1);
			} else {
				map.put(str, 1);
			}
		}
		Set<Entry<String, Integer>> entry = map.entrySet();
		for (Entry<String,Integer> ent: entry) {
			if (ent.getValue()>max) {
				max = ent.getValue();
				label = ent.getKey();
			}
		}
		return label;
	}
	public static void classfy(ArrayList<ArrayList<String>> dataset ,ArrayList<ArrayList<String>> testData,int k) {
		int index = 0;
		int count = 0;
		for (ArrayList<String> testItem : testData) {
			String str=getFeatureLabel(dataset, testItem, k);
			System.out.println(str);
			if (testItem.get((testData.get(0).size()-1)).equals(str)) {
				System.out.println("testItem"+index+"分类正确");
				count ++;
			} else {
				System.out.println("testItem"+index+"分类错误");
			}
			index ++;
		}
		System.out.println("正确率为"+count*1.0/testData.size());
	}
	public static void main(String[] args) {
		// TODO Auto-generated method stub

		String path = new String("D:/weather.txt");
		String path2 = new String("D:/weather2.txt");
		ArrayList<ArrayList<String>> dataSet = formatData(loadFile(path));
		ArrayList<ArrayList<String>> testSet = formatData(loadFile(path2));
		classfy(dataSet, testSet, 2);;
	   }
    }
     

算法中已经把注释去掉，实现的主要函数介绍，如下
1. loadFile函数，所做的工作是加载文件用的，包括读取测试文件和训练集文件。
2. getColum函数，取的数据集中的每一列属性值的集合并排序，为类后面的归一化处理。
3. getMaxMin函数，求属性值集合中的最小值与最大值。同样是为了归一化处理数据
4. formatData函数，格式归一化数据。
5. showArray函数，打印数组。
6. caldistance函数，计算距离的函数
7. getFeatureLabel函数，得到预测的结果类别

### 4 实验及分析

实验中对于数据集Haberman.txt，使用其中的一部分作为测试集，另一部分作为训练集进行测试测试的结果正确率有0.7291666666666666。对于算法后续的工作是在数据预处理这块，对于连续属性离散化的操作。提高算法正确率和通用性需要有更多的测试集，检验模型的分类能力。